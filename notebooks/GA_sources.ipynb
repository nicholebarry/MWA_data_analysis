{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a2f233b-51e0-4cc6-ad73-140fb9689274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7c2c059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imaging with more data; template from wk2 folder\n",
    "import astropy \n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from astropy.io import ascii\n",
    "from scipy.signal import convolve2d\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# FWHM = 0.07913  / 12   # psf HWHM is an assumption\n",
    "# sigma_FWHM = FWHM / 2.355\n",
    "# HWHM = FWHM / 2\n",
    "# sigma_HWHM = HWHM/ 1.177\n",
    "\n",
    "\n",
    "more_data = open('/Users/nicholebarry/MWA/data/Deconvolution/observation_ids.txt', 'r')\n",
    "component_array = [line.split( ) for line in more_data.readlines()]\n",
    "    \n",
    "for i in component_array:\n",
    "    components = '/Users/nicholebarry/MWA/data/Deconvolution/' + i[0] +'_components.fits'\n",
    "    hdu_list = fits.open(components, memmap=True)\n",
    "\n",
    "    info_array = hdu_list[1].data\n",
    "\n",
    "    ra = info_array['RIGHTASCENSION']\n",
    "    dec = info_array['DECLINATION']\n",
    "    flux = info_array['FLUXI']\n",
    "    #used eyed instead of id since id is already a taken name\n",
    "    eyed = info_array['ID']\n",
    "    beam = info_array['BEAM']\n",
    "\n",
    "    \n",
    "    # appropriate range for ra is [340,10] which goes over the 360 boundary, to mitigate this we add an offset such that the effective ra range is [-20, 10]!\n",
    "    ra[ra>180] -= 360\n",
    "\n",
    "\n",
    "    # here i am setting up the initial data in the array by putting the data from the first fits file in the array.\n",
    "    if component_array[0] == i:\n",
    "        ra_overall = ra\n",
    "        dec_overall = dec\n",
    "        eyed_overall = eyed\n",
    "        flux_overall = flux\n",
    "        beam_overall = beam\n",
    "    #for all else, it appends to the new variable to make a REALLY BIG ARRAY OF EVERYTHING EVER\n",
    "    else:\n",
    "        ra_overall = np.append(ra_overall, ra)\n",
    "        dec_overall = np.append(dec_overall, dec)\n",
    "        eyed_overall = np.append(eyed_overall, eyed)\n",
    "        flux_overall = np.append(flux_overall, flux)\n",
    "        beam_overall = np.append(beam_overall, beam)\n",
    "\n",
    "\n",
    "\n",
    "#represents the total number of observations\n",
    "n_obs = len(component_array)\n",
    "\n",
    "def pixelate(ra_zoom, dec_zoom, n_bins, ra_overall, dec_overall, eyed_overall, flux_overall):\n",
    "\n",
    "    #Check to see which dimension is larger so that a square in ra,dec can \n",
    "    #be returned\n",
    "    if (ra_zoom[1]-ra_zoom[0]) > (dec_zoom[1]-dec_zoom[0]):\n",
    "        zoom = ra_zoom\n",
    "    else:\n",
    "        zoom = dec_zoom\n",
    "\n",
    "    #Find the size of the bins using the largest dimension and the num of bins\n",
    "    binsize = (zoom[1]-zoom[0])/n_bins\n",
    "\n",
    "    #Create arrays for ra and dec that give the left side of each pixel\n",
    "    ra_bin_array = np.multiply(range(n_bins), binsize) + ra_zoom[0]\n",
    "    dec_bin_array = np.multiply(range(n_bins), binsize) + dec_zoom[0]\n",
    "\n",
    "    #Create an empty array of pixels to be filled in the for loops\n",
    "    pixels = np.zeros((len(ra_bin_array),len(dec_bin_array)))\n",
    "\n",
    "    #Histogram components into ra bins\n",
    "    ra_histogram = np.digitize(ra_overall,ra_bin_array)\n",
    "\n",
    "    #Begin for loop over both dimensions of pixels, starting with ra\n",
    "    for bin_i in range(len(ra_bin_array) - 2):\n",
    "\n",
    "        #Find the indices that fall into the current ra bin slice\n",
    "        ra_inds = np.where(ra_histogram == bin_i)\n",
    "\n",
    "        #Go to next for cycle if no indices fall into current ra bin slice\n",
    "        if len(ra_inds) == 0:\n",
    "            continue\n",
    "\n",
    "        #Histogram components that fall into the current ra bin slice by dec\n",
    "        dec_histogram = np.digitize(dec_overall[ra_inds],dec_bin_array)\n",
    "\n",
    "        #Begin for loop by dec over ra bin slice\n",
    "        for bin_j in range(len(dec_bin_array) - 2):\n",
    "            \n",
    "            #Find the indicies that fall into the current dec bin\n",
    "            dec_inds = np.where(dec_histogram == bin_j)\n",
    "\n",
    "            #Go to next for cycle if no indices fall into current dec bin\t\t\t\n",
    "            if len(dec_inds) == 0:\n",
    "                continue\n",
    "\n",
    "            #Sum the flux components that fall into current ra/dec bin\n",
    "            pixels[bin_i,bin_j] = np.sum(flux_overall[(ra_inds[0])[dec_inds[0]]])\n",
    "\n",
    "    #Find the pixel centers in ra/dec for plotting purposes\n",
    "    ra_pixel_centers = np.multiply(range(n_bins),binsize) + ra_zoom[0] + binsize/2.\n",
    "    dec_pixel_centers = np.multiply(range(n_bins),binsize) + dec_zoom[0] + binsize/2.\n",
    "\n",
    "    return pixels, ra_pixel_centers, dec_pixel_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3da9d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_sigma =  3.5000884642604446\n",
      "normalized ker mult. amplitude :\n",
      " [[8.16917909e-73 2.96492996e-71 9.91744136e-70 ... 9.91744136e-70\n",
      "  2.96492996e-71 8.16917909e-73]\n",
      " [2.96492996e-71 1.07609462e-69 3.59944600e-68 ... 3.59944600e-68\n",
      "  1.07609462e-69 2.96492996e-71]\n",
      " [9.91744136e-70 3.59944600e-68 1.20398442e-66 ... 1.20398442e-66\n",
      "  3.59944600e-68 9.91744136e-70]\n",
      " ...\n",
      " [9.91744136e-70 3.59944600e-68 1.20398442e-66 ... 1.20398442e-66\n",
      "  3.59944600e-68 9.91744136e-70]\n",
      " [2.96492996e-71 1.07609462e-69 3.59944600e-68 ... 3.59944600e-68\n",
      "  1.07609462e-69 2.96492996e-71]\n",
      " [8.16917909e-73 2.96492996e-71 9.91744136e-70 ... 9.91744136e-70\n",
      "  2.96492996e-71 8.16917909e-73]]\n",
      "ker 1.0\n",
      "flux sum:  8.435489833706106\n",
      "tot flux 8.435489833706102\n",
      "new_sigma =  1.4000353857041667\n",
      "normalized ker mult. amplitude :\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "ker 0.9999999999999999\n",
      "flux sum:  0.4108591731790392\n",
      "tot flux 0.4108591731790392\n",
      "new_sigma =  3.1500796178343506\n",
      "normalized ker mult. amplitude :\n",
      " [[3.44095275e-89 2.90002801e-87 2.20983187e-85 ... 2.20983187e-85\n",
      "  2.90002801e-87 3.44095275e-89]\n",
      " [2.90002801e-87 2.44413774e-85 1.86244183e-83 ... 1.86244183e-83\n",
      "  2.44413774e-85 2.90002801e-87]\n",
      " [2.20983187e-85 1.86244183e-83 1.41918744e-81 ... 1.41918744e-81\n",
      "  1.86244183e-83 2.20983187e-85]\n",
      " ...\n",
      " [2.20983187e-85 1.86244183e-83 1.41918744e-81 ... 1.41918744e-81\n",
      "  1.86244183e-83 2.20983187e-85]\n",
      " [2.90002801e-87 2.44413774e-85 1.86244183e-83 ... 1.86244183e-83\n",
      "  2.44413774e-85 2.90002801e-87]\n",
      " [3.44095275e-89 2.90002801e-87 2.20983187e-85 ... 2.20983187e-85\n",
      "  2.90002801e-87 3.44095275e-89]]\n",
      "ker 1.0\n",
      "flux sum:  0.45956697934841517\n",
      "tot flux 0.4595669793484152\n",
      "new_sigma =  2.2500568698817016\n",
      "normalized ker mult. amplitude :\n",
      " [[4.23815031e-172 2.52112502e-168 1.23092100e-164 ... 1.23092100e-164\n",
      "  2.52112502e-168 4.23815031e-172]\n",
      " [2.52112502e-168 1.49972769e-164 7.32231165e-161 ... 7.32231165e-161\n",
      "  1.49972769e-164 2.52112502e-168]\n",
      " [1.23092100e-164 7.32231165e-161 3.57506554e-157 ... 3.57506554e-157\n",
      "  7.32231165e-161 1.23092100e-164]\n",
      " ...\n",
      " [1.23092100e-164 7.32231165e-161 3.57506554e-157 ... 3.57506554e-157\n",
      "  7.32231165e-161 1.23092100e-164]\n",
      " [2.52112502e-168 1.49972769e-164 7.32231165e-161 ... 7.32231165e-161\n",
      "  1.49972769e-164 2.52112502e-168]\n",
      " [4.23815031e-172 2.52112502e-168 1.23092100e-164 ... 1.23092100e-164\n",
      "  2.52112502e-168 4.23815031e-172]]\n",
      "ker 1.0\n",
      "flux sum:  0.49871605918666384\n",
      "tot flux 0.4987160591866638\n",
      "new_sigma =  3.1500796178343506\n",
      "normalized ker mult. amplitude :\n",
      " [[3.44095275e-89 2.90002801e-87 2.20983187e-85 ... 2.20983187e-85\n",
      "  2.90002801e-87 3.44095275e-89]\n",
      " [2.90002801e-87 2.44413774e-85 1.86244183e-83 ... 1.86244183e-83\n",
      "  2.44413774e-85 2.90002801e-87]\n",
      " [2.20983187e-85 1.86244183e-83 1.41918744e-81 ... 1.41918744e-81\n",
      "  1.86244183e-83 2.20983187e-85]\n",
      " ...\n",
      " [2.20983187e-85 1.86244183e-83 1.41918744e-81 ... 1.41918744e-81\n",
      "  1.86244183e-83 2.20983187e-85]\n",
      " [2.90002801e-87 2.44413774e-85 1.86244183e-83 ... 1.86244183e-83\n",
      "  2.44413774e-85 2.90002801e-87]\n",
      " [3.44095275e-89 2.90002801e-87 2.20983187e-85 ... 2.20983187e-85\n",
      "  2.90002801e-87 3.44095275e-89]]\n",
      "ker 1.0\n",
      "flux sum:  8.546094215795643\n",
      "tot flux 8.546094215795645\n",
      "new_sigma =  1.5750398089172033\n",
      "normalized ker mult. amplitude :\n",
      " [[0.000000e+000 0.000000e+000 0.000000e+000 ... 0.000000e+000\n",
      "  0.000000e+000 0.000000e+000]\n",
      " [0.000000e+000 0.000000e+000 0.000000e+000 ... 0.000000e+000\n",
      "  0.000000e+000 0.000000e+000]\n",
      " [0.000000e+000 0.000000e+000 3.932674e-318 ... 3.932674e-318\n",
      "  0.000000e+000 0.000000e+000]\n",
      " ...\n",
      " [0.000000e+000 0.000000e+000 3.932674e-318 ... 3.932674e-318\n",
      "  0.000000e+000 0.000000e+000]\n",
      " [0.000000e+000 0.000000e+000 0.000000e+000 ... 0.000000e+000\n",
      "  0.000000e+000 0.000000e+000]\n",
      " [0.000000e+000 0.000000e+000 0.000000e+000 ... 0.000000e+000\n",
      "  0.000000e+000 0.000000e+000]]\n",
      "ker 1.0\n",
      "flux sum:  1.1972580032697955\n",
      "tot flux 1.1972580032697957\n",
      "new_sigma =  1.400035385704189\n",
      "normalized ker mult. amplitude :\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "ker 1.0\n",
      "flux sum:  12.629943053864064\n",
      "tot flux 12.629943053864064\n",
      "new_sigma =  2.6250663481953076\n",
      "normalized ker mult. amplitude :\n",
      " [[3.63832862e-127 2.15746490e-124 1.10652665e-121 ... 1.10652665e-121\n",
      "  2.15746490e-124 3.63832862e-127]\n",
      " [2.15746490e-124 1.27933875e-121 6.56150847e-119 ... 6.56150847e-119\n",
      "  1.27933875e-121 2.15746490e-124]\n",
      " [1.10652665e-121 6.56150847e-119 3.36528486e-116 ... 3.36528486e-116\n",
      "  6.56150847e-119 1.10652665e-121]\n",
      " ...\n",
      " [1.10652665e-121 6.56150847e-119 3.36528486e-116 ... 3.36528486e-116\n",
      "  6.56150847e-119 1.10652665e-121]\n",
      " [2.15746490e-124 1.27933875e-121 6.56150847e-119 ... 6.56150847e-119\n",
      "  1.27933875e-121 2.15746490e-124]\n",
      " [3.63832862e-127 2.15746490e-124 1.10652665e-121 ... 1.10652665e-121\n",
      "  2.15746490e-124 3.63832862e-127]]\n",
      "ker 1.0\n",
      "flux sum:  0.2590844922958583\n",
      "tot flux 0.2590844922958583\n",
      "new_sigma =  0.6300159235668791\n",
      "normalized ker mult. amplitude :\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "ker 0.9984178797860107\n",
      "flux sum:  18.39487468396298\n",
      "tot flux 18.36577178089168\n",
      "new_sigma =  1.0500265392781294\n",
      "normalized ker mult. amplitude :\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "ker 0.9999999985866225\n",
      "flux sum:  12.257908654750372\n",
      "tot flux 12.257908637425315\n"
     ]
    }
   ],
   "source": [
    "def gaussian_kernel(size, new_sigma):\n",
    "    # make 1D array of equally spaced intervals\n",
    "    array = np.linspace((-(size - 1) / 2), ((size - 1) / 2), size)\n",
    "    # turns 1D array into 2D Kernel thingy\n",
    "    x, y = np.meshgrid(array, array)\n",
    "    kernel = np.exp(-0.5 * (np.square(x) + np.square(y)) / np.square(new_sigma))\n",
    "    amplitutde = 1/(np.square(new_sigma)*2*np.pi)\n",
    "    #print(\"exp:\",( -0.5 * (np.square(x) + np.square(y)) / np.square(new_sigma)))\n",
    "    #print(\"kernel\\n\", kernel)\n",
    "    s = kernel #/ np.sum(kernel)\n",
    "    amp = s * amplitutde\n",
    "\n",
    "    print(\"normalized ker mult. amplitude :\\n\", amp)\n",
    "    return amp\n",
    "\n",
    "divider = 16\n",
    "FWHM = 0.07913  / divider  # psf HWHM is an assumption 8, 24\n",
    "sigma_FWHM = FWHM / 2.355\n",
    "\n",
    "\n",
    "#for loop here to loop through all the sources\n",
    "#centre the sources so each source is the same number of pixels and therefore has the same ra and dec [5.95, 6.05]\n",
    "\n",
    "ra_sources = [[5.75, 5.84], [3.15, 3.375], [2.50, 2.60], [0.83, 0.97], [-2.35, -2.25], [-11.10, -10.90], [-10.125, -9.90], [5.94, 6.06], [-1.00, -0.50], [11.75, 12.05]]\n",
    "dec_sources = [[-25.09,-25], [-28.75,-28.525], [-29.34,-29.24],[-27.48,-27.34],[-25,-24.9], [-28.5,-28.3],[-27.575,-27.35 ], [-30.42,-30.3],[-35,-34.5], [-25.45, -25.15]]\n",
    "n_bins = 150 \n",
    "\n",
    "#create a loop to find the difference between the 2nd and first components of each element in the array to find the degree range\n",
    "degree_range = []\n",
    "for pair in dec_sources:\n",
    "    diff = pair[1] - pair[0]\n",
    "    degree_range.append(diff)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "\n",
    "for ra_zoom, dec_zoom in zip(ra_sources, dec_sources):\n",
    "\n",
    "    range_of_ra_dec = np.where((ra_overall >= ra_zoom[0]) & (ra_overall <= ra_zoom[1]) & (dec_overall >= dec_zoom[0]) & (dec_overall <= dec_zoom[1]))\n",
    "    \n",
    "    new_ra = ra_overall[range_of_ra_dec]\n",
    "    new_dec = dec_overall[range_of_ra_dec]\n",
    "    new_flux = flux_overall[range_of_ra_dec]\n",
    "    new_eyed = eyed_overall[range_of_ra_dec]\n",
    "    new_beam = beam_overall[range_of_ra_dec]\n",
    "\n",
    "\n",
    "    (pixels, ra_pixel_centers, dec_pixel_centers) = pixelate(ra_zoom, dec_zoom, n_bins, new_ra, new_dec, new_eyed, new_flux)\n",
    "\n",
    "    pixels2 = pixels / n_obs\n",
    "    num = np.size(pixels2)\n",
    "    \n",
    "\n",
    "# divide num of pixels by the degree range so wehave pixels/deg then multiply with sigma_HWHM so we have the sigma in the unit of pixels then pass that through the function\n",
    "   # max_sigma = 1.33\n",
    "    new_sigma =  (np.sqrt(num) / (degree_range[counter]) * (sigma_FWHM))\n",
    "    counter += 1\n",
    "    print(\"new_sigma = \", new_sigma)\n",
    "    size = 90\n",
    "    kernel = gaussian_kernel(size, new_sigma)\n",
    "    kernel_sum = np.sum(kernel)\n",
    "    print(\"ker\", kernel_sum)\n",
    "    print(\"flux sum: \", np.sum(pixels2))\n",
    "    conv_image = convolve2d(pixels2,kernel)\n",
    "    print(\"tot flux\", np.sum(conv_image))\n",
    "\n",
    "\n",
    "    with open('/Users/nicholebarry/MWA/data/Deconvolution/flux_data_'+ str(divider) +'_'+ str(size)+'.txt', 'a') as file:\n",
    "    # Iterate through the pixel centers and their corresponding flux values\n",
    "    # Write source information\n",
    "        file.write(f\"source {counter}\\n\")\n",
    "        for i, ra in enumerate(ra_pixel_centers):\n",
    "            for j, dec in enumerate(dec_pixel_centers):\n",
    "                flux_value = conv_image[i, j]\n",
    "            # Write the RA, Dec, and flux value to the file\n",
    "                file.write(f\"{ra}, {dec}, {flux_value}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b3f6f4e7-4849-48ab-9a20-2f9dd096c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 1\n",
      "source 2\n",
      "source 3\n",
      "source 4\n",
      "source 5\n",
      "source 6\n",
      "source 7\n",
      "source 8\n",
      "source 9\n",
      "source 10\n",
      "9555\n",
      "9.699568714030711\n",
      "11.873 12.049\n"
     ]
    }
   ],
   "source": [
    "ra = [[] for _ in range(10)]\n",
    "dec = [[] for _ in range(10)]\n",
    "flux = [[] for _ in range(10)]\n",
    "freq = 182.435\n",
    "\n",
    "source_i = 0\n",
    "initial_i = 0\n",
    "count_i = 0\n",
    "\n",
    "file_path = '/Users/nicholebarry/MWA/data/Deconvolution/flux_data_40_90.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line.lower().startswith('source'):\n",
    "            print(line)\n",
    "            if initial_i != 0:\n",
    "                source_i += 1\n",
    "                continue\n",
    "            initial_i += 1\n",
    "            continue\n",
    "        \n",
    "        array = line.split(',')\n",
    "\n",
    "        #if float(array[2]) != 0:\n",
    "        if float(array[2]) > 1E-4:\n",
    "            if initial_i == 1:\n",
    "                count_i = count_i + 1\n",
    "            ra[source_i].append(float(array[0]))\n",
    "            dec[source_i].append(float(array[1]))\n",
    "            flux[source_i].append(float(array[2]))\n",
    "\n",
    "print(count_i)\n",
    "print(np.sum(np.array(flux[9][1:], dtype=float)))\n",
    "print(np.min(np.array(ra[9][1:])), np.max(np.array(ra[9][1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "622a1b5f-c29a-437e-8550-ef72e3a90c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/nicholebarry/MWA/data/Deconvolution/srclist_pumav3_EoR0LoBES_EoR1pietro_CenA-GP_2023-11-07.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU     42   348067R x 14C   ['16A', '20A', 'D', 'D', 'D', 'D', 'D', '3A', '1A', 'D', 'D', 'D', 'D', 'D']   \n",
      "  2                1 BinTableHDU     16   10280R x 4C   [20A, K, K, D]   \n",
      "9\n",
      "11.875 12.049\n",
      "-25.275 -25.150999999999996\n",
      "(array([    72,     73,     75,     82,     83, 292190]),)\n",
      "7.678238675929833 3.756620168031001\n",
      "XTENSION= 'BINTABLE'           / binary table extension                         BITPIX  =                    8 / array data type                                NAXIS   =                    2 / number of array dimensions                     NAXIS1  =                  120 / length of dimension 1                          NAXIS2  =               348067 / length of dimension 2                          PCOUNT  =                    0 / number of group parameters                     GCOUNT  =                    1 / number of groups                               TFIELDS =                   14 / number of table fields                         TTYPE1  = 'UNQ_SOURCE_ID'                                                       TFORM1  = '16A     '                                                            TTYPE2  = 'NAME    '                                                            TFORM2  = '20A     '                                                            TTYPE3  = 'RA      '                                                            TFORM3  = 'D       '                                                            TUNIT3  = 'deg     '                                                            TTYPE4  = 'DEC     '                                                            TFORM4  = 'D       '                                                            TUNIT4  = 'deg     '                                                            TTYPE5  = 'MAJOR_DC'                                                            TFORM5  = 'D       '                                                            TUNIT5  = 'deg     '                                                            TTYPE6  = 'MINOR_DC'                                                            TFORM6  = 'D       '                                                            TUNIT6  = 'deg     '                                                            TTYPE7  = 'PA_DC   '                                                            TFORM7  = 'D       '                                                            TUNIT7  = 'deg     '                                                            TTYPE8  = 'MOD_TYPE'                                                            TFORM8  = '3A      '                                                            TUNIT8  = 'deg     '                                                            TTYPE9  = 'COMP_TYPE'                                                           TFORM9  = '1A      '                                                            TTYPE10 = 'NORM_COMP_PL'                                                        TFORM10 = 'D       '                                                            TTYPE11 = 'ALPHA_PL'                                                            TFORM11 = 'D       '                                                            TTYPE12 = 'NORM_COMP_CPL'                                                       TFORM12 = 'D       '                                                            TTYPE13 = 'ALPHA_CPL'                                                           TFORM13 = 'D       '                                                            TTYPE14 = 'CURVE_CPL'                                                           TFORM14 = 'D       '                                                            END                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/nicholebarry/MWA/data/Deconvolution/srclist_pumav3_EoR0LoBES_EoR1pietro_CenA-GP_2023-11-07.fits'\n",
    "\n",
    "with fits.open(file_path) as hdul:\n",
    "    catalog = hdul[1].data  # Assuming the catalog is in the first extension\n",
    "    header = hdul[1].header\n",
    "    hdul.info()\n",
    "\n",
    "# Create a new FITS table with the updated ra_array and dec_array\n",
    "new_catalog = catalog.copy()\n",
    "\n",
    "# Convert to an Astropy Table\n",
    "table = Table(catalog)\n",
    "# print(header)\n",
    "\n",
    "# Print the column names\n",
    "#print(table.colnames)\n",
    "\n",
    "for source_i in range(1):\n",
    "\n",
    "    source_i=9\n",
    "    print(source_i)\n",
    "    \n",
    "    # Adjust RA values greater than 180\n",
    "    inds_ra = np.where(new_catalog['ra'] > 180)\n",
    "    new_catalog['ra'][inds_ra] -= 360\n",
    "\n",
    "    ra_array = np.array(ra[source_i][1:], dtype=float)\n",
    "    len_ra_array = len(ra_array)\n",
    "    #print(len_ra_array)\n",
    "    #print(np.min(ra_array))\n",
    "    dec_array = np.array(dec[source_i][1:], dtype=float)\n",
    "    flux_array = np.array(flux[source_i][1:], dtype=float)\n",
    "    \n",
    "    max_ra = np.max(ra_array)\n",
    "    min_ra = np.min(ra_array)\n",
    "    if max_ra > 180:\n",
    "        max_ra -= 360\n",
    "    if min_ra > 180:\n",
    "        min_ra -= 360\n",
    "\n",
    "    max_dec = np.max(dec_array)\n",
    "    min_dec = np.min(dec_array)\n",
    "    print(min_ra, max_ra)\n",
    "    print(min_dec, max_dec)\n",
    "    \n",
    "    inds_source_i = np.where((new_catalog['ra'] > min_ra) & (new_catalog['ra'] < max_ra) & \n",
    "                             (new_catalog['dec'] > min_dec) & (new_catalog['dec'] < max_dec))\n",
    "\n",
    "    alpha = np.nanmean(new_catalog['ALPHA_PL'][inds_source_i])\n",
    "    if np.isnan(alpha):\n",
    "        alpha = np.nanmean(new_catalog['ALPHA_CPL'][inds_source_i])\n",
    "    new_flux = flux_array * (200.0 / 182.435) ** alpha\n",
    "    print(inds_source_i)\n",
    "    print(np.nansum(new_flux), np.nansum(new_catalog['NORM_COMP_CPL'][inds_source_i]))\n",
    "\n",
    "    inds_keep = np.where((new_catalog['ra'] < min_ra) | (new_catalog['ra'] > max_ra) & \n",
    "                        (new_catalog['dec'] < min_dec) | (new_catalog['dec'] > max_dec))\n",
    "    #inds_keep = np.where((new_catalog['dec'] < min_dec) & (new_catalog['dec'] > max_dec))\n",
    "\n",
    "    \n",
    "    new_catalog['ra'][inds_ra] += 360\n",
    "    \n",
    "    new_ids = np.array(['GA' + str(i) for i in range(len(ra_array))])\n",
    "    new_COMP_TYPE = np.array(['P' for i in range(len(ra_array))])\n",
    "    new_MOD_TYPE = np.array(['pl' for i in range(len(ra_array))])\n",
    "\n",
    "    id_array = np.concatenate([new_catalog['UNQ_SOURCE_ID'][inds_keep], new_ids])\n",
    "    ra_array = np.concatenate([new_catalog['ra'][inds_keep], ra_array])\n",
    "    dec_array = np.concatenate([new_catalog['dec'][inds_keep], dec_array])\n",
    "    flux_array = np.concatenate([new_catalog['NORM_COMP_PL'][inds_keep], new_flux])\n",
    "    alpha_array = np.concatenate([new_catalog['ALPHA_PL'][inds_keep], np.full(len_ra_array, alpha)])\n",
    "    \n",
    "    name_array = np.concatenate([new_catalog['NAME'][inds_keep], np.zeros(len_ra_array)])\n",
    "    MAJOR_DC_array = np.concatenate([new_catalog['MAJOR_DC'][inds_keep], np.zeros(len_ra_array)])\n",
    "    MINOR_DC_array = np.concatenate([new_catalog['MINOR_DC'][inds_keep], np.zeros(len_ra_array)])\n",
    "    PA_DC_array = np.concatenate([new_catalog['PA_DC'][inds_keep], np.zeros(len_ra_array)])\n",
    "    MOD_TYPE_array = np.concatenate([new_catalog['MOD_TYPE'][inds_keep], new_MOD_TYPE])\n",
    "    COMP_TYPE_array = np.concatenate([new_catalog['COMP_TYPE'][inds_keep], new_COMP_TYPE])\n",
    "    norm_comp_cpl_array = np.concatenate([new_catalog['NORM_COMP_CPL'][inds_keep], np.zeros(len_ra_array)])\n",
    "    ALPHA_CPL_array = np.concatenate([new_catalog['ALPHA_CPL'][inds_keep], np.zeros(len_ra_array)])\n",
    "    CURVE_CPL_array = np.concatenate([new_catalog['CURVE_CPL'][inds_keep], np.zeros(len_ra_array)])\n",
    "\n",
    "    # Create new FITS columns\n",
    "    id_col = Column(name='UNQ_SOURCE_ID', data=id_array, format='16A')\n",
    "    name_col = Column(name='NAME', data=name_array, format='20A')\n",
    "    ra_col = Column(name='ra', data=ra_array, format='D')\n",
    "    dec_col = Column(name='dec', data=dec_array, format='D')\n",
    "    major_dc_col = Column(name='MAJOR_DC', data=MAJOR_DC_array, format='D')\n",
    "    minor_dc_col = Column(name='MINOR_DC', data=MINOR_DC_array, format='D')\n",
    "    pa_dc_col = Column(name='PA_DC', data=PA_DC_array, format='D')\n",
    "    mod_type_col = Column(name='MOD_TYPE', data=MOD_TYPE_array, format='3A')\n",
    "    comp_type_col = Column(name='COMP_TYPE', data=COMP_TYPE_array, format='1A')\n",
    "    flux_col = Column(name='NORM_COMP_PL', data=flux_array, format='D')\n",
    "    alpha_col = Column(name='ALPHA_PL', data=alpha_array, format='D')\n",
    "    norm_comp_cpl_col = Column(name='NORM_COMP_CPL', data=norm_comp_cpl_array, format='D')\n",
    "    alpha_cpl_col = Column(name='ALPHA_CPL', data=ALPHA_CPL_array, format='D')\n",
    "    curve_cpl_col = Column(name='CURVE_CPL', data=CURVE_CPL_array, format='D')\n",
    "\n",
    "\n",
    "    \n",
    "    # Create a new FITS table with these columns\n",
    "    new_catalog = Table([id_col, name_col, ra_col, dec_col, major_dc_col, minor_dc_col, pa_dc_col, mod_type_col, comp_type_col, flux_col, alpha_col, norm_comp_cpl_col, alpha_cpl_col, curve_cpl_col])\n",
    "\n",
    "    \n",
    "    # new_catalog['UNQ_SOURCE_ID'] = id_array\n",
    "    # new_catalog['RA'] = ra_array\n",
    "    # new_catalog['DEC'] = dec_array\n",
    "    # new_catalog['NORM_COMP_PL'] = flux_array\n",
    "    # new_catalog['ALPHA_PL'] = alpha_array\n",
    "    # new_catalog['NAME'] = name_array\n",
    "    # new_catalog['MAJOR_DC'] = MAJOR_DC_array\n",
    "    # new_catalog['MINOR_DC'] = MINOR_DC_array\n",
    "    # new_catalog['PC_DC'] = PA_DC_array\n",
    "    # new_catalog['MOD_TYPE'] = MOD_TYPE_array\n",
    "    # new_catalog['COMP_TYPE'] = COMP_TYPE_array\n",
    "    # new_catalog['ALPHA_CPL'] = ALPHA_CPL_array\n",
    "    # new_catalog['CURVE_CPL'] = CURVE_CPL_array\n",
    "\n",
    "\n",
    "\n",
    "    # # Create a new FITS HDU (Header/Data Unit) with the updated data\n",
    "    # new_hdu = fits.BinTableHDU(data=new_data, header=original_header)\n",
    "    \n",
    "    # # Write the new FITS file\n",
    "    # new_file_path = 'path_to_your_new_fits_file.fits'\n",
    "    # new_hdu.writeto(new_file_path, overwrite=True)\n",
    "\n",
    "\n",
    "# Create a new FITS HDU (Header/Data Unit) with the updated data\n",
    "\n",
    "    # Create a new FITS HDU (Header/Data Unit) with these columns\n",
    "id_col = fits.Column(name='UNQ_SOURCE_ID', array=id_array, format='16A')\n",
    "name_col = fits.Column(name='NAME', array=name_array, format='20A')\n",
    "ra_col = fits.Column(name='RA', array=ra_array, format='D')\n",
    "dec_col = fits.Column(name='DEC', array=dec_array, format='D')\n",
    "major_dc_col = fits.Column(name='MAJOR_DC', array=MAJOR_DC_array, format='D')\n",
    "minor_dc_col = fits.Column(name='MINOR_DC', array=MINOR_DC_array, format='D')\n",
    "pa_dc_col = fits.Column(name='PA_DC', array=PA_DC_array, format='D')\n",
    "mod_type_col = fits.Column(name='MOD_TYPE', array=MOD_TYPE_array, format='3A')\n",
    "comp_type_col = fits.Column(name='COMP_TYPE', array=COMP_TYPE_array, format='1A')\n",
    "flux_col = fits.Column(name='NORM_COMP_PL', array=flux_array, format='D')\n",
    "alpha_col = fits.Column(name='ALPHA_PL', array=alpha_array, format='D')\n",
    "norm_comp_cpl_col = fits.Column(name='NORM_COMP_CPL', array=norm_comp_cpl_array, format='D')\n",
    "alpha_cpl_col = fits.Column(name='ALPHA_CPL', array=ALPHA_CPL_array, format='D')\n",
    "curve_cpl_col = fits.Column(name='CURVE_CPL', array=CURVE_CPL_array, format='D')\n",
    "cols = fits.ColDefs([id_col, name_col, ra_col, dec_col, major_dc_col, minor_dc_col, pa_dc_col, mod_type_col, comp_type_col, flux_col, alpha_col, norm_comp_cpl_col, alpha_cpl_col, curve_cpl_col])\n",
    "new_hdu = fits.BinTableHDU.from_columns(cols)\n",
    "\n",
    "# Update the header to match the new columns\n",
    "new_hdu.header.extend(header, update=True)\n",
    "\n",
    "print(header)\n",
    "\n",
    "# Write the new FITS file\n",
    "new_file_path = '/Users/nicholebarry/MWA/data/Deconvolution/srclist_pumav3_EoR0LoBES_EoR1pietro_CenA-GP_2023-11-07_GA16_90_1_1e-4.fits'\n",
    "new_hdu.writeto(new_file_path, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e344021e-2565-4a9f-9c5a-7d59224e0871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /Users/z3543600/Downloads/flux_data_fixed/srclist_pumav3_EoR0LoBES_EoR1pietro_CenA-GP_2023-11-07_GA8_90_1_smaller.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1                1 BinTableHDU     34   352335R x 13C   ['16A', '20A', 'D', 'D', 'D', 'D', 'D', '3A', '1A', 'D', 'D', 'D', 'D']   \n",
      "XTENSION= 'BINTABLE'           / binary table extension                         BITPIX  =                    8 / array data type                                NAXIS   =                    2 / number of array dimensions                     NAXIS1  =                  112 / length of dimension 1                          NAXIS2  =               352335 / length of dimension 2                          PCOUNT  =                    0 / number of group parameters                     GCOUNT  =                    1 / number of groups                               TFIELDS =                   13 / number of table fields                         TTYPE1  = 'UNQ_SOURCE_ID'                                                       TFORM1  = '16A     '                                                            TTYPE2  = 'NAME    '                                                            TFORM2  = '20A     '                                                            TTYPE3  = 'RA      '                                                            TFORM3  = 'D       '                                                            TTYPE4  = 'DEC     '                                                            TFORM4  = 'D       '                                                            TTYPE5  = 'MAJOR_DC'                                                            TFORM5  = 'D       '                                                            TTYPE6  = 'MINOR_DC'                                                            TFORM6  = 'D       '                                                            TTYPE7  = 'PA_DC   '                                                            TFORM7  = 'D       '                                                            TTYPE8  = 'MOD_TYPE'                                                            TFORM8  = '3A      '                                                            TTYPE9  = 'COMP_TYPE'                                                           TFORM9  = '1A      '                                                            TTYPE10 = 'ALPHA_PL'                                                            TFORM10 = 'D       '                                                            TTYPE11 = 'NORM_COMP_PL'                                                        TFORM11 = 'D       '                                                            TTYPE12 = 'ALPHA_CPL'                                                           TFORM12 = 'D       '                                                            TTYPE13 = 'CURVE_CPL'                                                           TFORM13 = 'D       '                                                            END                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "file_path = '/Users/z3543600/Downloads/flux_data_fixed/srclist_pumav3_EoR0LoBES_EoR1pietro_CenA-GP_2023-11-07_GA8_90_1_smaller.fits'\n",
    "\n",
    "with fits.open(file_path) as hdul:\n",
    "    catalog = hdul[1].data  # Assuming the catalog is in the first extension\n",
    "    header = hdul[1].header\n",
    "    hdul.info()\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89364dbf-1411-4173-be9d-18aa3638c543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
